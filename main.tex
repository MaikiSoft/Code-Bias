\documentclass[conference]{IEEEtran}

% Language setting
% Replace `english' with e.g. `spanish' to change the document language
\usepackage[english]{babel}

% Useful packages
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{url}

% Title and author info
\title{Coded Bias}
\author{\IEEEauthorblockN{Michael Esteban Castillo Lopez, 506221049}}

\begin{document}
\maketitle

\begin{abstract}
El documental “coded bias” destaca la influencia significativa de la tecnología en la sociedad moderna, incluyendo el potencial de los algoritmos para perpetuar sesgos raciales y de género. La investigadora Joy Buolamwini del MIT Media Lab descubre cómo estos sesgos pueden manifestarse en herramientas tecnológicas, como un algoritmo en hospitales de EE. UU. que favorecía a pacientes blancos sobre negros, basándose en costos de atención médica previos, una métrica sesgada por desigualdades en el acceso a la salud.

El análisis se sumerge en los desafíos de la inteligencia artificial (IA) en relación con la interfaz de usuario (UI) y la experiencia de usuario (UX). Se enfatiza la importancia de la diversidad en el diseño de UI para evitar marginar a usuarios y la necesidad de crear sistemas de IA transparentes y justos para una UX confiable y equitativa. El documental cuestiona cómo asegurar la objetividad de la IA y sugiere pruebas rigurosas, equipos multidisciplinarios y una reflexión ética continua.

Se observan similitudes entre “coded bias” y un caso real de sesgo en un algoritmo médico, ambos ejemplificando el impacto del sesgo inconsciente y la falta de diversidad en los datos y equipos de desarrollo. La transparencia es crucial para mitigar sesgos tanto en IA de reconocimiento facial como en algoritmos médicos.

Finalmente, se abordan las diferencias en las variables y componentes técnicos entre los casos y se resalta la responsabilidad ética de los desarrolladores y empresas en la creación de IA equitativa y socialmente responsable, subrayando la importancia de la transparencia, la rendición de cuentas y la participación de una diversidad de voces en el desarrollo de la IA.
\end{abstract}

\section{Introduction}

En la era digital actual, la tecnología ejerce un poder innegable en nuestras vidas, moldeando decisiones que van desde nuestros hábitos de consumo hasta los diagnósticos médicos. Sin embargo, esta influencia no es del todo benigna. El documental "Sesgo Codificado" expone una realidad alarmante: los algoritmos, a menudo percibidos como objetivos e imparciales, pueden perpetuar y amplificar sesgos raciales y de género.\\

Este descubrimiento, realizado por la investigadora Joy Buolamwini del MIT Media Lab, pone de relieve la urgente necesidad de examinar y corregir las herramientas tecnológicas que dan forma a nuestra sociedad.\\

La relevancia de "Sesgo Codificado" no se limita al ámbito teórico; se ve reflejada en casos reales que evidencian las repercusiones tangibles del sesgo algorítmico. Un ejemplo particularmente impactante, descubierto en octubre de 2019, revela que un algoritmo utilizado en hospitales de EE. UU. para la atención médica favorecía a pacientes blancos sobre pacientes negros a la hora de recibir atención adicional. A pesar de no utilizar directamente la raza como variable, el algoritmo se basaba en el historial de costos de atención médica, una métrica indirectamente sesgada por las desigualdades sistémicas en el acceso a la salud. Este caso pone de manifiesto la importancia de la transparencia y la responsabilidad en el desarrollo y la implementación de tecnologías que pueden afectar profundamente la vida de las personas.

\section{Desarrollo}

\subsection{Análisis }


El documental "Coded Bias" ofrece una inmersión profunda en los desafíos que enfrenta la inteligencia artificial (IA) en relación con la interfaz de usuario (UI) y la experiencia de usuario (UX), al evidenciar cómo los sesgos inconscientes pueden infiltrarse en los sistemas de IA, alterando la interacción del usuario con la tecnología.\\

Explorando la Interfaz de Usuario (UI), el documental resalta la crítica importancia de considerar la diversidad al diseñar interfaces, ya que aquellas creadas sin este factor en mente pueden dejar a ciertos usuarios marginados. Por ejemplo, las tecnologías de reconocimiento facial que no están entrenadas para identificar correctamente a personas de diferentes etnias pueden generar experiencias discriminatorias y excluyentes. En este contexto, se destaca la necesidad de diseñar interfaces inclusivas, garantizando que sean accesibles y funcionales para todos los usuarios, independientemente de su origen étnico, género, edad o habilidades físicas.\\

En cuanto a la Experiencia de Usuario (UX), el documental pone de relieve cómo los sesgos presentes en los sistemas de IA pueden erosionar la confianza del usuario en la tecnología. Por ejemplo, cuando un algoritmo médico muestra preferencia por pacientes de determinada raza o género, la confianza en la imparcialidad y precisión del sistema se ve comprometida. Por lo tanto, la UX debe centrarse en la creación de sistemas transparentes y justos que fomenten la confianza y la equidad entre los usuarios, asegurando que sus experiencias sean positivas y libres de sesgos discriminatorios.\\

El documental también plantea interrogantes cruciales sobre el diseño de sistemas de IA: ¿Cómo podemos garantizar que estos sistemas sean justos y objetivos? La respuesta implica la implementación de pruebas rigurosas y diversas durante el desarrollo, la formación de equipos multidisciplinarios que incorporen diversas perspectivas en el proceso de diseño, y una reflexión continua sobre las implicaciones éticas de la IA en todas sus etapas.\\

Por otra parte, se sugiere que una parte esencial para mejorar la UI/UX en la IA radica en educar a diseñadores y desarrolladores sobre los sesgos inconscientes y cómo mitigarlos. El fomento de la conciencia y la formación en temas de diversidad, equidad e inclusión puede conducir a la adopción de mejores prácticas de diseño y al desarrollo de sistemas de IA más justos y equitativos para todos los usuarios.\\


\subsection{Contraste con el caso real: Similitudes}

Sesgo Inconsciente: Tanto en “Coded Bias” como en el caso del algoritmo de atención médica, se evidencia el sesgo inconsciente en los sistemas de IA. Ambos muestran cómo la falta de diversidad en los datos y en los equipos de desarrollo puede llevar a resultados sesgados.\\[12pt]
Impacto en Grupos Vulnerables: En ambos casos, los grupos vulnerables son los más afectados por el sesgo algorítmico. El documental y el caso real destacan cómo las personas de color pueden ser desfavorecidas por sistemas que no han sido diseñados con su representación en mente.\\[12pt]
Necesidad de Transparencia: La transparencia es crucial tanto en la IA de reconocimiento facial como en los algoritmos de atención médica. La capacidad de examinar y corregir los algoritmos es esencial para mitigar el sesgo.

\subsection{Contraste con el caso real: Diferencias}

Variables Utilizadas: En “Coded Bias”, el problema surge de la incapacidad de los algoritmos para reconocer correctamente a personas de diferentes etnias. En el caso del algoritmo de atención médica, el sesgo proviene de la correlación entre el historial de costos de atención médica y la raza, sin que la raza sea una variable directa.\\[12pt]
Componentes Técnicos: El algoritmo de atención médica utilizaba datos históricos de costos para predecir la necesidad de atención médica futura, mientras que los sistemas de reconocimiento facial dependen del procesamiento de imágenes y aprendizaje visual.\\[12pt]
Respuesta y Corrección: Mientras que en el caso del algoritmo de atención médica se trabajó con la empresa Optum para reducir el sesgo, “Coded Bias” aboga por una mayor conciencia y regulación en general, sin una solución única y directa.


\subsection{Contraste con el caso real: Componentes eticos}

Equidad: Ambos casos plantean preguntas éticas sobre la equidad y la justicia en la IA. ¿Cómo podemos garantizar que la tecnología sirva a todos por igual? La equidad en la inteligencia artificial es fundamental para asegurar que los beneficios y riesgos de la tecnología se distribuyan de manera justa entre todas las personas y comunidades. Esto implica abordar y mitigar los sesgos que puedan estar presentes en los datos de entrenamiento y en los algoritmos mismos. Además, es crucial involucrar a una diversidad de voces en el proceso de desarrollo de la IA para garantizar que las perspectivas de grupos históricamente marginados se tomen en cuenta. La implementación de políticas y regulaciones que promuevan la transparencia y la rendición de cuentas también es esencial para asegurar que la IA no perpetúe o amplíe las desigualdades existentes.\\[12pt]
Responsabilidad:  La responsabilidad de los desarrolladores y las empresas es central en ambos escenarios. Se destaca la importancia de la ética en el diseño y la implementación de algoritmos. Los desarrolladores de IA deben adherirse a principios éticos sólidos, asegurando que sus creaciones no solo sean técnicamente competentes, sino también socialmente responsables. Esto incluye considerar las implicaciones a largo plazo de sus tecnologías y trabajar para minimizar el potencial de daño. Las empresas que implementan IA deben ser transparentes acerca de cómo y por qué se utilizan sus algoritmos, proporcionando explicaciones claras y accesibles sobre las decisiones automatizadas. La creación de mecanismos de supervisión y auditoría independientes puede ayudar a mantener altos estándares de responsabilidad y a detectar posibles mal usos de la tecnología de manera oportuna. En última instancia, la responsabilidad compartida entre desarrolladores, empresas, reguladores y usuarios es clave para construir una IA que respete y promueva los valores humanos fundamentales.



\section{Conclusiones}

los diseñadores de UI/UX tienen la responsabilidad única de moldear la interacción entre los usuarios y la tecnología. Los casos expuestos en “Coded Bias” y el algoritmo de atención médica resaltan la importancia crítica de diseñar con una perspectiva ética y consciente. Para abordar estos desafíos de manera efectiva, los diseñadores deben:\\

Incorporar la Diversidad en el Proceso de Diseño: Asegurar que los equipos de diseño incluyan una amplia gama de perspectivas y experiencias. Esto puede ayudar a identificar y mitigar los sesgos inconscientes desde el principio.\\
Realizar Pruebas Rigurosas y Representativas: Utilizar conjuntos de datos diversos y realizar pruebas exhaustivas en diferentes grupos demográficos para garantizar que los sistemas de IA funcionen equitativamente para todos los usuarios.\\
Fomentar la Transparencia y la Explicabilidad: Diseñar interfaces que permitan a los usuarios entender cómo y por qué se toman decisiones automatizadas. Esto es esencial para construir confianza y permitir la rendición de cuentas.\\
Adoptar un Marco Ético: Desarrollar y seguir un conjunto de principios éticos que guíen todas las fases del diseño y desarrollo de la IA, desde la concepción hasta la implementación y el monitoreo continuo.\\
Promover la Educación Continua: Mantenerse informados sobre los últimos avances en IA y ética, y buscar activamente formación en áreas como la diversidad, la inclusión y la justicia social.\\
Al centrarse en estos aspectos, los diseñadores de UI/UX no solo mejorarán la calidad y la accesibilidad de las interfaces y experiencias que crean, sino que también contribuirán a una sociedad más justa y equitativa en la que la tecnología sirva a todos por igual.\\



\bibliographystyle{IEEEtran}
\bibliography{sample}
Kantayya Shalini. Coded Bias. (26 de mayo de 2021). [Video en línea]. Disponible: https://www.netflix.com/title/81328723\\

Modern Health Care. “Sesgo en atención al paciente: construyendo una inteligencia artificial imparcial”. revista salud digital latinoamerica. [En línea]. Disponible: https://www.revistasaluddigital.com/es/noticia/sesgo-en-atencion-al-paciente-construyendo-una-inteligencia-artificial-imparcial\\

P. Giménez-Bonafé y T. Cabanillas-Montferrer, “EL SESGO DE GÉNERO EN LA ASISTENCIA SANITARIA: DEFINICIÓN, CAUSAS Y CONSECUENCIAS EN LOS PACIENTES”, Musas, vol. 7, n.º 1, p. 24, 2022.\\

\end{document}

